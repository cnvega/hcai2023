{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0437e732-fece-4669-8b6a-d1ef9d1b2c49",
   "metadata": {},
   "source": [
    "Probamos que la librería de acceso a archivos HDF5 de Python, `h5py`, funciona correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4192c2b3-24a5-49a6-a1cc-510dd76f67f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ca696dd-cb3a-4149-b48a-8d73fdcdaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un archivo en modo escritura\n",
    "f = h5py.File(\"test.h5\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6641b5f9-955e-43dd-8db8-8d6ae0cacb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo cerramos:\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d62840-27d8-475f-beec-4ecc69eb3a3c",
   "metadata": {},
   "source": [
    "### Tipos de datos que almacena un HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cecbad-1e6f-4806-873a-c1b8ffac85dc",
   "metadata": {},
   "source": [
    "#### Grupos:\n",
    "Podemos crear grupos en un archivo, aunque estos se pueden crear automáticamente al momento de guardar un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85a475c8-3f5c-45c2-aac9-af7af557600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo anterior en modo lectura y escritura:\n",
    "f = h5py.File(\"test.h5\", \"r+\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f2f9ff5-f77d-40cb-86dd-08952bc1ed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Data\" (0 members)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.create_group(\"Header\")\n",
    "f.create_group(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e972bf86-7435-4f13-b479-6762f4206899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Header']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para consultar lo que hay en un archivo, usamos .keys()\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ed815c6-6271-4c80-bb2d-3409f6e6c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e897e-564b-40e8-b0d6-096ebe410133",
   "metadata": {},
   "source": [
    "#### Datasets:\n",
    "Podemos crear datasets vacios (de cierto tamaño y tipo de dato definido), así como \"llenos\" directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ddfac06-5a10-4e4d-a58f-67d0799f287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datos del ejemplo de la clase:\n",
    "import numpy as np\n",
    "\n",
    "rand1 = np.loadtxt(\"datos.txt\", usecols=[1], unpack=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84c54196-4066-4271-9651-51d03ac06287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos nuevamente el archivo en modo r+:\n",
    "f = h5py.File(\"test.h5\", \"r+\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beadee79-723e-484b-9499-27da74e9d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos nuestro array:\n",
    "f[\"rand1\"] = rand1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced72177-c115-4b61-a4da-3221d8693dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f432190-7926-4f96-9520-736907252939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También puedo agregar datos dentro de los grupos:\n",
    "f = h5py.File(\"test.h5\", \"r+\") \n",
    "f[\"Data/rand2\"] = rand1+10.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb7dc214-ffe7-43c9-aab4-b2873759fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fcd6f1a-f6eb-459b-849c-301b8872f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluso, los grupos nuevos se crean automáticamente al momento de almacenar un dataset:\n",
    "f = h5py.File(\"test.h5\", \"r+\") \n",
    "f[\"DataBad/rand3\"] = rand1/0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1dcf94b-6bf0-4160-bc12-308ab6253617",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f44b2-94bc-4d2c-ac9d-146346ef9856",
   "metadata": {},
   "source": [
    "Para leer los datos, utilizamos la misma estrategia que los objetos compuestos de numpy utilizando el objeto que contiene el archivo HDF5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8269fe2-7982-4182-906c-0790c048a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"test.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06e46467-87f2-40c6-abd9-5ffc3f8b92c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.750514,  1.513391, -0.257402,  2.42373 , -0.937215,  0.607678,\n",
       "       -0.802247, -0.03792 , -1.16919 , -1.32793 , -1.44829 ,  0.434063,\n",
       "       -0.888893,  1.350377, -0.389023,  0.154864, -1.156754, -1.201204,\n",
       "       -0.622379,  0.389723,  0.584301,  1.207718,  0.113014, -1.357977,\n",
       "       -0.048609, -0.230104, -0.647716,  0.394307,  0.467628,  0.684698,\n",
       "        1.343784,  0.045572,  0.888684,  1.378604,  0.309605, -0.115059,\n",
       "        0.074366,  1.317366,  2.239764,  0.195176, -1.171153, -1.399296,\n",
       "       -0.244733,  0.890791, -0.007609, -0.335468,  0.807286,  1.854221,\n",
       "        0.395264,  0.748414])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utilizando el label y el operador de indexación se puede acceder al contenido del archivo:\n",
    "f['rand1'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "694ee360-c914-4273-ab4d-9b2c8a6f6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para trabajar con los datos del HDF5, es conveniente copiar los valores a la memoria RAM:\n",
    "mi_array= f['rand1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc4f044-92f8-430e-8670-49c911b224a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.750514,  1.513391, -0.257402, ...,  0.629598,  0.037971,\n",
       "        0.256897])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85e013b8-c4db-4bbd-b013-c82cd0268b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b6729-90ad-4b38-b0be-eecd46db3ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
